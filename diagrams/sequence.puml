@startuml
autonumber

actor Player
participant "AiCommand" as Command
participant "ConversationManager" as Convo
participant "RateLimiter" as RL
participant "OllamaClient" as Client
participant "Ollama Server" as Ollama
participant "ToolDispatcher" as Dispatch
participant "ToolHandlers" as Tools

Player -> Command : /ai chat "message"

Command -> RL : check(player)
RL --> Command : allowed

Command -> Convo : appendPlayerMessage()
Command -> Convo : getConversation()
Convo --> Command : context messages

Command -> Client : sendPrompt(model, context)\n<<async>>

Client -> Ollama : HTTP POST /generate
Ollama --> Client : text + toolCalls JSON
Client --> Command : CompletableFuture<OllamaResponse>

Command -> Convo : appendModelMessage()

alt response includes toolCalls
    loop for each toolCall
        Command -> Dispatch : execute(toolCall)
        Dispatch -> Tools : validate + run on main thread
        Tools --> Dispatch : ToolResult
        Dispatch -> Convo : appendToolResult()
    end
end

Command -> Player : final response text

@enduml
